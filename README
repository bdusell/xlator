==== DESCRIPTION ====

This project is a natural language translator based on context free grammars.
Although the parsing and translation algorithms currently used in this program
were conceived independently (and somewhat naively) by the author, it closely
resembles a very simple implementation of the concepts of a Chomskyan
transformational grammar, except that transformations are used to mutate parse
trees from an input language into those of an output language instead of
mapping them to a deep structure.

The program is currently in a working state, and if you have the patience to
learn what this program is all about and are fond of Chomskyan linguistics, I
encourage you try your hand at writing your own grammar/translation file pairs
and develop your own powerful natural language processor. The syntax and
mechanics of these files should be fairly easy to understand given the
examples. Maybe you could get it do you your homework for you. ;)

==== BUILDING ====

The Makefile builds two executables: xlator and xlator-debug. The latter is a
version of the program compiled with all sorts of debug flags and output turned
on and lets you take a peek at what's going on under the hood. The regular
xlator program is far more taciturn and simply reads a line of output in the
input language and spits out all possible translations, one per line, of this
input string or else reports any errors encountered in the input or in the
translation process.

To build both targets:
    % (cd src && make)

==== EXAMPLE USAGE ====

The xlator program accepts exactly two command line arguments: the first is a
grammar file which specifies what strings of tokens are accepted by the input
language. The second is a translation file which specifies the rules used for
transforming pieces of parse tree in the input language to pieces of parse tree
in the output language. This format requires a little bit of explanation and a
rudimentary understanding of how the translation algorithm works. Let's look at
a very simple (but plausible) example of a translation rule.

<*jp-predicate> { <en-verb> { v } <en-noun-phrase> { n } } -> <*jp-predicate> { <*jp-noun-phrase> { n } "o" <*jp-verb> { v } }

Keep in mind that in translation files, two disjoint symbol alphabets are in
play. For clarity, in this example, any non-terminal symbol (i.e.
<anything-written-like-this>) belonging to the input alphabet is prefixed with
"en-", and any non-terminal belonging to the output alphabet is prefixed with
"*jp-". Note that the braces indicate parse tree hierarchy and that the "->"
symbol separates the left and right sides of the rule. Anything in double
quotes is a terminal symbol (which cannot have children). The bare "v" and "n"
symbols which appear on both sides are wildcards which stand for a string of
sub-trees beneath a non-terminal symbol.

The left side of a translation rule is a parse tree *pattern*, which is said to
match the top of a partially translated input parse tree if all of the terminal
and nonterminal symbols in the input tree match those in the pattern and in the
same tree structure. Anything else in the input tree must be accounted for in
the wildcard variables. Note that non-terminal symbols can never be leaf nodes
-- they must always contain either a string of sub-trees to match or a
placeholder variable for them. The placeholder variables on the right side
refer to those on the left and indicate how the unmatched sub-trees in the
input parse tree are donated to the newly constructed tree on the right side.
In this example, the non-terminals <en-verb> and <en-noun-phrase> are
basically re-named and switched, and it is expected that new translation rules
will be applied recursively to the newly created <*jp-noun-phrase> and
<*jp-verb> symbols, which have the old child sets of <en-noun-phrase> and
<en-verb>, respectively.

The root node on the left side belongs to the output alphabet, and anything
beneath it belongs to the input alphabet. This reflects the fact the
translation algorithm works by starting at the root node of the input parse
tree and then working its way down, matching the top of the tree with
translation rules, applying the transformations described by those rules,
donating child nodes of the input tree to those of the output tree, and
continuing the process recursively on the non-terminal leaf nodes of the
transformed tree.

Refer to the examples under test/ for additional guidance. Note that these
translation files always start with a rule of the form

<sentence> { x } -> <*sentence> { x }

where <sentence> is in the input alphabet and also the start variable of the
input grammar, and <*sentence> is in the output alphabet. This rule serves as
the first matched rule and starts the recursive translation procedure. For this
reason, whenever a non-terminal variable on the left side is the root node
and also has a wildcard for its children, it is considered to be in the input
alphabet.

The xlator program accepts a single line of input on stdin and, barring any
errors in the input files or the syntax of the input line, exhaustively prints
out all possible translations, one per line, to stdout.

The input string is read as a sequence of case-sensitive tokens, which are
delineated by white space. This tokenization method is currently not very
intelligent and does not even permit sentence capitalization (at least not
in a way that doesn't involve tweaking the input grammar in a ludricous way).

The program works with ASCII and UTF-8 character encodings.

Both the grammar and translation files can include '#'-style comments;
everything after the first '#' character on a line not inside of a token is
ignored.

Examples:

English to Japanese:

    % ./bin/xlator test/a.gram.txt test/a.trans.txt
    the man sees the woman
    otoko no hito wa onna no hito o mimasu

English to Latin:

    % ./bin/xlator test/testgrammar1.txt test/testtranslator1.txt
    the teacher teaches the student
    magister discipulum docet
    magister discipulam docet
    magister docet discipulum
    magister docet discipulam
    magistra discipulum docet
    magistra discipulam docet
    magistra docet discipulum
    magistra docet discipulam
    discipulum docet magister
    discipulum docet magistra
    discipulam docet magister
    discipulam docet magistra
    docet discipulum magister
    docet discipulum magistra
    docet discipulam magister
    docet discipulam magistra

Pretty cool, eh?

==== TODO ====

* Re-write the parser to use Tomita's GLR algorithm.
* Validate the input grammar for acyclicity.
* Add a tool for checking translation files for completeness with respect to
  the input grammar.
* Implement a more flexible system of rule matching which uses symbol
  attributes as the basis of comparison.
* Provide more sophisticated methods of specifying grammar rules which make it
  easier to produce simple, clean parse trees for the translation grammar to
  use.
* Allow translation grammars to be chained -- perhaps by accepting additional
  translation grammars from the command line and applying them in succession.
* Allow rules to be split across lines somehow.
* Allow non-terminal leaf nodes in the translation file to have no explicit
  child set; drop the children of a childless leaf on the left side and
  possibly provide a way to specify all possible alternations of a childless
  leaf node on the right side.
* Use more library features from C++11 and boost, e.g. shared_ptr.

